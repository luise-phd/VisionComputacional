{"cells":[{"cell_type":"markdown","metadata":{"id":"nFIZyVqD_Dyu"},"source":["## Cargando redes pre-entrenadas\n","Las redes preentrenadas son modelos que ya han sido entrenados con grandes conjuntos de datos, como ImageNet, y pueden ser reutilizados para resolver tareas similares sin necesidad de entrenarlos desde cero. En Keras, puedes cargar fácilmente arquitecturas populares como ResNet, VGG, MobileNet o Inception, lo que permite aprovechar su capacidad de generalización y ahorrar tiempo computacional.\n","\n","Puedes explorar las opciones disponibles en el siguiente enlace: https://keras.io/applications/"]},{"cell_type":"markdown","source":["## Elaborado por: Luis Eduardo Ordoñez"],"metadata":{"id":"EQSoHgAoR7WC"}},{"cell_type":"markdown","source":["### Importar librerías"],"metadata":{"id":"FjpqtKDHS6q6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cuYkROQg_Dyw"},"outputs":[],"source":["import numpy as np\n","import cv2\n","\n","from google.colab.patches import cv2_imshow\n","\n","# Importa el modelo ResNet50 preentrenado desde la biblioteca Keras Applications\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","# Importa utilidades para cargar y procesar imágenes\n","from tensorflow.keras.preprocessing import image\n","# Importa funciones específicas de ResNet50 para preprocesar imágenes y decodificar predicciones\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"]},{"cell_type":"markdown","source":["### ResNet50\n","Es una arquitectura de red neuronal convolucional profunda compuesta por 50 capas, diseñada para tareas de clasificación de imágenes. Fue propuesta por Microsoft Research y es parte de la familia de redes Residual Networks (ResNet), cuya principal innovación es el uso de \"conexiones residuales\" o atajos que permiten entrenar redes muy profundas sin sufrir problemas de degradación del aprendizaje. Gracias a estas conexiones, ResNet50 puede aprender representaciones visuales complejas de forma más eficiente, superando en precisión a modelos anteriores como VGG. Entrenado en el conjunto de datos ImageNet, ResNet50 es ampliamente utilizado para transfer learning y aplicaciones prácticas en visión computacional, como reconocimiento de objetos, detección de rostros y análisis de imágenes médicas."],"metadata":{"id":"HQaxjdwCShZ1"}},{"cell_type":"code","source":["# Carga el modelo ResNet50 con pesos preentrenados en ImageNet\n","# Este modelo puede reconocer miles de clases visuales comunes\n","model = ResNet50()"],"metadata":{"id":"o-MhGXVQTAQQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conectar Google Colab con Google Drive"],"metadata":{"id":"WiUshm_aP6XN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"mkHCkfQCP5rZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Función para mostrar imagen"],"metadata":{"id":"aNl1KOXdUk_G"}},{"cell_type":"code","source":["def mostrar_img(imagen):\n","  # Obtener dimensiones originales\n","  alto, ancho = imagen.shape[:2]\n","\n","  # Definir nuevo ancho deseado\n","  nuevo_ancho = 400\n","\n","  # Calcular nuevo alto proporcional\n","  proporcion = nuevo_ancho / ancho\n","  nuevo_alto = int(alto * proporcion)\n","\n","  # Redimensionar con proporción conservada\n","  imagen_redim = cv2.resize(imagen, (nuevo_ancho, nuevo_alto))\n","\n","  # Mostrar imagen\n","  cv2_imshow(imagen_redim)\n","  print()"],"metadata":{"id":"C6QSf0_tUnqY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Función para clasificar la imagen"],"metadata":{"id":"pyKBj4BxlMxz"}},{"cell_type":"code","source":["def predecir_img(img_path):\n","  # Carga la imagen desde la ruta y la redimensiona al tamaño requerido por ResNet50 (224x224 píxeles)\n","  img = image.load_img(img_path, target_size=(224, 224))\n","\n","  # Convierte la imagen a un arreglo NumPy (matriz de píxeles)\n","  x = image.img_to_array(img)\n","\n","  # Expande las dimensiones del arreglo para simular un lote (batch) de una sola imagen\n","  x = np.expand_dims(x, axis=0)\n","\n","  # Aplica el preprocesamiento específico requerido por ResNet50 (reescala y normaliza la imagen)\n","  x = preprocess_input(x)\n","\n","  # Realiza la predicción utilizando el modelo ResNet50\n","  preds = model.predict(x)\n","\n","  # Muestra las predicciones decodificadas (nombre de clase e índice de confianza)\n","  print('Predicciones:')\n","  for n in decode_predictions(preds)[0]:\n","      print(n[1:])  # Muestra solo el nombre de la clase y la probabilidad (sin el ID de clase)"],"metadata":{"id":"w6Vv_joLlI4r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"4JBzIXTDlY0G"}},{"cell_type":"code","source":["# Editar la ruta local en Google Drive de la imagen que se va a visualizar\n","img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/bufalo.jpg')\n","mostrar_img(img)\n","\n","# Editar la ruta local en Google Drive de la imagen que se va a clasificar\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/bufalo.jpg'\n","predecir_img(img_path)"],"metadata":{"id":"lIRPj2uZj6-C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"v5qBf9lbVW2a"}},{"cell_type":"code","source":["img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/elephant.jpg')\n","mostrar_img(img)\n","\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/elephant.jpg'\n","predecir_img(img_path)"],"metadata":{"id":"qcaDgy46lq_f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"F3a0glkhZHFE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2M4a-oKY_Dyy"},"outputs":[],"source":["img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/jabali.jpg')\n","mostrar_img(img)\n","\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/jabali.jpg'\n","predecir_img(img_path)"]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"rvWSD0ueWFD3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Lpdc7BI_Dyz"},"outputs":[],"source":["img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/pirarucu.jpg')\n","mostrar_img(img)\n","\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/pirarucu.jpg'\n","predecir_img(img_path)"]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"6JvqvK36WO2L"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mw7v0p_-_Dy0"},"outputs":[],"source":["img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/tilapia.jfif')\n","mostrar_img(img)\n","\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/tilapia.jfif'\n","predecir_img(img_path)"]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"L8OUkM_9WMqu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeDgZjhY_Dy1"},"outputs":[],"source":["img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/landscape.jpg')\n","mostrar_img(img)\n","\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/landscape.jpg'\n","predecir_img(img_path)"]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"6guTTQzKXRk3"}},{"cell_type":"code","source":["img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/arbol.png')\n","mostrar_img(img)\n","\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/arbol.png'\n","predecir_img(img_path)"],"metadata":{"id":"fsFKIJ84YQdn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ver y clasificar imagen"],"metadata":{"id":"WZDA2s0zZSzW"}},{"cell_type":"code","source":["img = cv2.imread('/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/laptop.jpg')\n","mostrar_img(img)\n","\n","img_path = '/content/drive/MyDrive/Corhuila/Visión Computacional/Notebooks/imgs/laptop.jpg'\n","predecir_img(img_path)"],"metadata":{"id":"CMhEgc1SXSDi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fq90yBDG_Dy1"},"source":["## Otras redes de detección de objetos en  tiempo real:\n","Clasificación de imágenes con localización de objetos:\n","https://pjreddie.com/darknet/yolo/"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}