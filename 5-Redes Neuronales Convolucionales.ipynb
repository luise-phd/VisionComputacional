{"cells":[{"cell_type":"markdown","metadata":{"id":"Q3Yd7xZSZHod"},"source":["# Redes Neuronales Convolucionales"]},{"cell_type":"markdown","metadata":{"id":"jZUhrgY-ZHoi"},"source":["<p style='text-align: justify;'>Las redes neuronales convolucionales son una extensión de las redes neuronales y son consideradas métodos de aprendizaje profundo. Generalmente se utilizan para el análisis y la clasificación de imágenes.</p>\n","\n","<p style='text-align: justify;'>La arquitectura de una red convolucional se basa en una secuencia de capas de neuronas, alternando entre capas convolucionales y capas de agrupación. Una representación clásica de las redes convolucionales es la siguiente:</p>\n","\n","<img src=\"https://raw.githubusercontent.com/luise-phd/VisionComputacional/refs/heads/main/imgs/CNN.png\"/>"]},{"cell_type":"markdown","metadata":{"id":"N78-PqwnZHok"},"source":["<p style='text-align: justify;'><b>Flattening</b> o aplanamiento es un paso que consiste en transformar los datos de entrada multidimensionales, como una imagen o un tensor tridimensional, en un vector unidimensional antes de pasarlos a una capa densa (fully connected) de la red.</p>"]},{"cell_type":"markdown","metadata":{"id":"bxSMzWiIZHon"},"source":["# Convolución y capas de convolución\n","\n","<p style='text-align: justify;'>La convolución no es un concepto nuevo, es una técnica que ha sido utilizada en el procesamiento de señales e imágenes.</p>\n","\n","<p style='text-align: justify;'>En el procesamiento de imágenes se utilizan filtros predefinidos para resaltar o disminuir ciertas características de las imágenes. Los filtros son aplicados en un barrido por toda la imagen para producir una imagen alterada.</p>"]},{"cell_type":"markdown","metadata":{"id":"kQCv9K7HZHop"},"source":["<table>\n","    <tr>\n","        <td><img src=\"https://github.com/luise-phd/VisionComputacional/blob/main/imgs/same_padding_no_strides.gif?raw=true\" /></td>\n","        <td><img src=\"https://github.com/luise-phd/VisionComputacional/blob/main/imgs/conv.gif?raw=true\" width=50% /></td>\n","    </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"QBCrW0KmZHpK"},"source":["## Capa de convolución"]},{"cell_type":"markdown","metadata":{"id":"zBmRbktiZHpL"},"source":["<p style='text-align: justify;'>En las redes de convolución los filtros utilizados no están definidos. Los filtros son \"aprendidos\" en tiempo de entrenamiento los cuales resaltan las características más importantes de la imagen. Como las redes construyen los filtros directamente a partir de la función de error, los filtros son más efectivos que cualquier filtro hecho manualmente por un humano.</p>\n","\n","<p style='text-align: justify;'>De hecho, la mayoría de las veces las redes de convolución generan filtros que capturan conceptos abstractos como por ejemplo el borde del mentón o la silueta de la oreja entre otras singularidades. Si agregamos más capas los filtros aprenden a capturar cosas más complejas como por ejemplo ojos o boca.</p>\n","\n","<p style='text-align: justify;'>El <b>objetivo de la convolución</b> es extraer las características de alto nivel desde una imagen de entrada.</p>\n","\n","<p style='text-align: justify;'>Algunos parámetros que podemos especificar son:</p>\n","\n","<ul>\n","    <li><b>filters:</b> Determina el número de filtros generados en la capa.</li>\n","    <li><b>padding:</b> Indica la forma que tendrá la imagen resultante después del barrido.</li>\n","    <li><b>kernel_size:</b> Determina el tamaño de los filtros creados.</li>\n","    <li><b>strides:</b> Determina el número de pixeles que debe ignorar entre movimientos del barrido.</li>\n","</ul>\n","\n","Puedes leer más sobre los parámetros en la documentación oficial:\n","https://keras.io/layers/convolutional/"]},{"cell_type":"markdown","metadata":{"id":"buNCCM9ZZHpL"},"source":["## Capa de agrupación"]},{"cell_type":"markdown","metadata":{"id":"8BkzgImnZHpM"},"source":["<p style='text-align: justify;'>La capa de agrupación funciona de una manera similar a la capa convolución donde se hace un recorrido a la imagen aplicando una función a cada sección de la imagen. El <b>objetivo de esta capa</b> es agrupar en una imagen las características más relevantes. Esto se realiza con 2 posibles funciones. La primera de ellas es obtener el valor máximo de la sección analizada y la segunda es obtener el promedio de la sección analizada.</p>\n","\n","Documentación oficial: https://keras.io/layers/pooling/"]},{"cell_type":"markdown","metadata":{"id":"SHrQZ2kmZHpN"},"source":["<table>\n","    <tr>\n","        <td><img src=\"https://github.com/luise-phd/VisionComputacional/blob/main/imgs/same_padding_no_strides.gif?raw=true\" width=80% /></td>\n","        <td><img src=\"https://github.com/luise-phd/VisionComputacional/blob/main/imgs/pooling.png?raw=true\" width=60% /></td>\n","    </tr>\n","</table>"]},{"cell_type":"markdown","source":["### Importar librerías"],"metadata":{"id":"kNN02xw-F5Qr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZP_UZdGZHoT"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import imread\n","# La función \"imread\" de \"pyplot\" se utiliza para leer y cargar imágenes y devuelve la imagen como un arreglo de NumPy.\n","\n","# Módulo 'keras' que proporciona herramientas para construir y entrenar redes neuronales de forma sencilla\n","from tensorflow import keras\n","\n","# Clases y funciones necesarias para construir modelos de Keras\n","from tensorflow.keras import layers, models\n","\n","# Conjunto de datos MNIST desde Keras (imágenes de dígitos manuscritos)\n","from tensorflow.keras.datasets import mnist\n","\n","# Scipy es una librería para realizar cálculos numéricos y científicos.\n","# El módulo \"signal\" permite acceder a todas las funciones y herramientas\n","# para procesar señales y realizar análisis de datos.\n","from scipy import signal\n","\n","# Sklearn es una librería para aprendizaje automático.\n","# Proporciona una variedad de herramientas y algoritmos para tareas como clasificación,\n","# regresión, clustering, reducción de dimensionalidad, selección de características, entre otros.\n","from sklearn.model_selection import train_test_split\n","\n","# Establecemos el modo de visualización de matplotlib a 'inline',\n","# lo que hará que las gráficas se muestren en el notebook\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"UZVnAxUTZHpO"},"source":["### Carga el conjunto de datos MNIST, que contiene imágenes de dígitos manuscritos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R50BZVVyZHpV"},"outputs":[],"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","print('Datos de entrenamiento:', x_train.shape)\n","print('Datos de entrenamiento:', x_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"HbEwUeOXZHpW"},"source":["# Construyendo y entrenando la NN"]},{"cell_type":"markdown","metadata":{"id":"sYYhc54MZHpX"},"source":["<img src=\"https://github.com/luise-phd/VisionComputacional/blob/main/imgs/CNN_detailed.png?raw=true\"/>"]},{"cell_type":"markdown","metadata":{"id":"Ekkv1WhoZHpY"},"source":["### Creación de la CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPPmKwgEZHpZ"},"outputs":[],"source":["input_layer = x_train\n","\n","# Crear un modelo secuencial vacío, que es una pila lineal de capas de red neuronal.\n","model = models.Sequential()\n","\n","# Creando capa Conv2D_1\n","# La capa tendrá 32 filtros convolucionales, que son matrices de pesos que se aplican a la imagen de entrada\n","# para extraer características.\n","# kernel_size especifica el tamaño de los filtros convolucionales como una tupla de dos valores.\n","# padding especifica el tipo de relleno (padding) que se utilizará para asegurarse de que la salida de la\n","# capa convolucional tenga la misma forma que la entrada.\n","# input_shape especifica la forma de entrada de la capa convolucional, que es una imagen en escala de grises\n","# de 28x28 píxeles con un canal de color (depth) de 1.\n","model.add( layers.Conv2D(filters = 32, kernel_size = (5, 5), activation='relu', padding=\"same\", input_shape=(28,28,1,)) )\n","\n","# Crear capa de agrupamiento Pooling2D_1\n","# La capa de agrupamiento máximo 2D reduce la dimensionalidad de la salida de la capa convolucional 2D anterior,\n","# mientras preserva la información más importante. Esto se hace mediante la división de la imagen de entrada en\n","# regiones de tamaño pool_size (2x2 en este caso), y seleccionando el valor máximo de cada región como salida.\n","# El parámetro strides especifica la cantidad de pasos (strides) a dar en la imagen de entrada antes de aplicar\n","# la operación de agrupamiento.\n","model.add( layers.MaxPooling2D(pool_size = (2, 2), strides=2) )\n","\n","# Crear capa Conv2D_2\n","# Se establece un número de filtros de 64, lo que significa que la capa extraerá 64 características\n","# diferentes de la entrada.\n","# El parámetro input_shape establece la forma de la entrada a la capa. En este caso, se establece en la\n","# forma de la capa de entrada anterior, lo que garantiza que la entrada a esta capa de convolución 2D\n","# tenga la misma forma que la salida de la capa de entrada.\n","model.add( layers.Conv2D(filters = 64, kernel_size = (5, 5), activation='relu', padding=\"same\", input_shape=input_layer.shape) )\n","\n","# Creando capa de agrupamiento Pooling2D_2\n","model.add( layers.MaxPooling2D(pool_size = (2, 2), strides=2) )\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"XzVpDDxPZHpa"},"source":["### Definición de Capas densas (totalmente conectadas) de la red neuronal\n","Son las capas que siguen a las capas convolucionales y de agrupamiento (pooling) en la arquitectura del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yr6z-UaGZHpb"},"outputs":[],"source":["# Esta capa toma los datos de la última capa convolucional y los aplana para que puedan ser procesados por\n","# una capa densa. Por ejemplo, si la salida de la última capa convolucional es un tensor de 4\n","# dimensiones (batch_size, height, width, channels), la capa Flatten lo convertirá en un tensor de 2\n","# dimensiones (batch_size, height x width x channels).\n","model.add(layers.Flatten())\n","\n","# capa densa tiene 64 neuronas, toma una entrada plana y calcula una salida mediante la multiplicación de una\n","# matriz de pesos y la adición de un vector de sesgos.\n","\n","model.add(layers.Dense(64, activation='relu'))\n","# La capa Dropout se utiliza para prevenir el sobreajuste del modelo. Esta capa elimina aleatoriamente\n","# algunas de las conexiones de la capa anterior durante el entrenamiento, lo que ayuda a evitar que la red\n","# se ajuste demasiado a los datos de entrenamiento. En este caso, el argumento rate especifica la fracción\n","# de conexiones que se eliminarán aleatoriamente en cada paso de entrenamiento (en este caso, el 40%).\n","\n","model.add(layers.Dropout(rate = 0.4))\n","model.add(layers.Dense(32, activation='relu'))\n","model.add(layers.Dropout(rate = 0.4))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# Resumen del modelo, incluyendo el número de parámetros entrenables en cada capa y el número total\n","# de parámetros en la red.\n","model.summary()"]},{"cell_type":"markdown","source":["### Compilar y entrenar el modelo"],"metadata":{"id":"eXqFIZ8bQ4mo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6kb7Gc7ZHpc"},"outputs":[],"source":["# La función de pérdida \"sparse_categorical_crossentropy\", se aplica a problemas de clasificación múltiple\n","# en los que las etiquetas son enteros y no se han codificado previamente en formato one-hot.\n","\n","# Se utiliza la métrica \"accuracy\" para medir la fracción de predicciones correctas realizadas por el\n","# modelo en el conjunto de datos de validación.\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=12, batch_size = 100);"]},{"cell_type":"markdown","metadata":{"id":"SAFtIdx7ZHpd"},"source":["<p style='text-align: justify;'>El número 600 indica que se han entrenado 600 lotes (o batches) de datos de 100 unidades cada lote durante cada época. El conjunto de entrenamiento tiene 60000 registros.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9Tj8bWsZHpe"},"outputs":[],"source":["test_loss, test_acc = model.evaluate(x_test, y_test)\n","print(\"Test acc:\", test_acc)"]},{"cell_type":"markdown","metadata":{"id":"Ay3frG5DZHpg"},"source":["<p style='text-align: justify;'>Indica que se está evaluando el modelo en el conjunto de datos de prueba. En este caso, el modelo ha procesado 313 muestras de prueba en 1 segundo con un promedio de pérdida y una precisión (accuracy).</p>"]},{"cell_type":"markdown","metadata":{"id":"n3elkeZ6ZHph"},"source":["# Probando la CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQbFnjzbZHph"},"outputs":[],"source":["predictions = model.predict(x_test)\n","y_hat = np.argmax(predictions, axis=1)"]},{"cell_type":"markdown","source":["### Resumen de datos"],"metadata":{"id":"89dbWi7LR-7T"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWHv9Vk9ZHpi"},"outputs":[],"source":["errores = x_test[y_test != y_hat]\n","print(\"Elementos de prueba: {}\".format(y_test.shape[0]))\n","errores_count = errores.shape[0]\n","errores_count\n","print(\"Errores identificados: {}\".format(errores_count))\n","porcentaje_error = errores_count * 100 / y_test.shape[0]\n","print(\"Porcentaje de error: {} %\".format(porcentaje_error))"]},{"cell_type":"markdown","source":["### Graficar las primeras 5 filas de errores"],"metadata":{"id":"TLWqtHkyRkxc"}},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"fnQIlNJFZHpk"},"outputs":[],"source":["real_labels = y_test[y_test != y_hat]\n","predicted_labels = y_hat[y_test != y_hat]\n","\n","k = 0\n","for j in range(round(errores.shape[0]/5)):\n","    plt.figure(figsize=(10,10))\n","    for i in range(min(5,errores_count-5*j)):\n","        plt.subplot(1,min(5,errores_count-5*j),i+1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        number = errores[5*j+i].reshape(28,28)\n","        plt.imshow(number, cmap=plt.cm.binary)\n","        plt.xlabel(\"Real: {} Prediccion: {}\".format\n","                   (real_labels[5*j+i],predicted_labels[5*j+i]))\n","    plt.show()\n","    k += 1\n","    if k == 5:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"BGxZ-BahZHpl"},"source":["# Matriz de confusión"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBpp7CInZHpm"},"outputs":[],"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","mod_confusion_matrix = confusion_matrix(y_test, y_hat)\n","for i in range(10):\n","    mod_confusion_matrix[i][i] = 0\n","\n","fig = plt.figure(figsize=(12,10))\n","ax = fig.add_subplot(1,1,1)\n","sns.heatmap(mod_confusion_matrix, linewidth=0.5, annot=True, cmap=\"YlGnBu\")\n","plt.ylabel(\"Etiquetas Reales\")\n","plt.xlabel(\"Etiquetas Predecidas\")\n","ax.set_ylim(10.5,-0.5);"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}