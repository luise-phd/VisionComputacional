{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPG1wUgCqs1FjuB2S9lcseE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Visualización de activaciones en una CNN entrenada con MNIST\n","Este Notebook  ilustra cómo una red neuronal convolucional (CNN) extrae características visuales jerárquicas, desde líneas simples hasta formas más complejas en capas profundas.\n","\n","Usaremos el conjunto de datos MNIST y visualizaremos los mapas de activación (feature maps) generados por las primeras capas de la CNN."],"metadata":{"id":"YvHDf-GWjWRs"}},{"cell_type":"markdown","source":["## Elaborado por: Luis Eduardo Ordoñez"],"metadata":{"id":"MaMOkahwjjEQ"}},{"cell_type":"markdown","source":["### Importar librerías"],"metadata":{"id":"mGlEw89gf5wd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ce21k-meEs9"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Biblioteca principal de TensorFlow\n","import tensorflow as tf\n","\n","# Clases y funciones necesarias para construir modelos de Keras\n","from tensorflow.keras import Input, Model, layers, models\n","\n","# Capas específicas para construir una red neuronal convolucional\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense\n","\n","# Conjunto de datos MNIST desde Keras (imágenes de dígitos manuscritos)\n","from tensorflow.keras.datasets import mnist"]},{"cell_type":"markdown","source":["### Cargar y preparar los datos"],"metadata":{"id":"AEyKLAyJfxaM"}},{"cell_type":"code","source":["# Carga el conjunto de datos MNIST, que contiene imágenes de dígitos manuscritos\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Selecciona solo una imagen del conjunto de prueba para ilustrar (la segunda imagen, índice 1)\n","x_test = x_test[1]\n","\n","# Ajusta la forma del array para que sea compatible con el modelo: (1, 28, 28, 1)\n","# Se añade una dimensión para el lote (batch) y otra para el canal (imagen en escala de grises)\n","x_test = x_test.reshape((-1, 28, 28, 1)) / 255.0  # Además, normaliza los valores de píxeles entre 0 y 1"],"metadata":{"id":"f0BdPcb6fw21"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Construir una CNN simple"],"metadata":{"id":"NoGwoZRegjdq"}},{"cell_type":"code","source":["# Definir la entrada de la red: imágenes de 28x28 píxeles con 1 canal (escala de grises)\n","inputs = Input(shape=(28, 28, 1))\n","\n","# Primera capa convolucional con 8 filtros de 3x3 y activación ReLU\n","x = Conv2D(8, (3, 3), activation='relu', name='conv1')(inputs)\n","\n","# Segunda capa convolucional con 16 filtros de 3x3 y activación ReLU\n","x = Conv2D(16, (3, 3), activation='relu', name='conv2')(x)\n","\n","# Aplanar la salida de la última convolución para conectar con capas densas\n","x = Flatten()(x)\n","\n","# Capa densa de salida con 10 neuronas (una por clase) y activación softmax\n","outputs = Dense(10, activation='softmax')(x)\n","\n","# Crear el modelo final especificando las entradas y salidas\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","# Compila el modelo especificando:\n","# - Optimizador: 'adam', que ajusta los pesos automáticamente durante el entrenamiento\n","# - Función de pérdida: 'sparse_categorical_crossentropy', adecuada para clasificación multiclase con etiquetas enteras\n","# - Métrica de evaluación: 'accuracy' para monitorear la precisión del modelo durante el entrenamiento\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Entrena el modelo usando el conjunto de entrenamiento\n","# - Las imágenes se normalizan dividiendo por 255.0\n","# - Se realiza el entrenamiento por 1 época (pasada completa por los datos)\n","# - Se usa un tamaño de lote (batch_size) de 128 ejemplos por iteración\n","model.fit(x_train.reshape(-1,28,28,1)/255.0, y_train, epochs=1, batch_size=128)"],"metadata":{"id":"oNOAaw0Jff9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Crear un modelo que devuelva activaciones"],"metadata":{"id":"N2o8s342gqij"}},{"cell_type":"code","source":["# Obtiene las salidas (activaciones) de todas las capas convolucionales del modelo\n","layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name]\n","\n","# Crea un nuevo modelo que, en lugar de predecir una clase, devuelve las activaciones intermedias\n","activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","\n","# Genera las activaciones para la imagen de prueba\n","activations = activation_model.predict(x_test)\n","\n","# Obtiene los nombres de las capas convolucionales para usar como títulos en las gráficas\n","layer_names = [layer.name for layer in model.layers if 'conv' in layer.name]\n","\n","# Itera por cada capa y sus activaciones correspondientes\n","for layer_name, layer_activation in zip(layer_names, activations):\n","    n_features = layer_activation.shape[-1]  # Número de mapas de activación (filtros)\n","    size = layer_activation.shape[1]         # Altura y ancho de cada mapa\n","\n","    # Crea una cuadrícula para visualizar todos los mapas de activación uno al lado del otro\n","    display_grid = np.zeros((size, size * n_features))\n","\n","    for i in range(n_features):\n","        activation = layer_activation[0, :, :, i]  # Extrae un mapa de activación\n","\n","        # Normaliza los valores del mapa para mejorar la visualización\n","        activation -= activation.mean()\n","        activation /= (activation.std() + 1e-5)\n","        activation *= 64\n","        activation += 128\n","        activation = np.clip(activation, 0, 255).astype('uint8')\n","\n","        # Inserta el mapa normalizado en la cuadrícula\n","        display_grid[:, i * size: (i + 1) * size] = activation\n","\n","    # Muestra la cuadrícula con las activaciones de una capa convolucional\n","    scale = 1.5\n","    plt.figure(figsize=(scale * n_features, scale))\n","    plt.title(f'Activaciones de la capa: {layer_name}')\n","    plt.grid(False)\n","    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n","    plt.show()"],"metadata":{"id":"pejjc-0weWUV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ¿Qué muestra este ejemplo?\n","* Las primeras capas resaltan bordes y contornos simples.\n","* Las capas más profundas combinan esas formas en patrones más complejos.\n","* Ayuda a visualizar cómo la red \"comprende\" una imagen paso a paso."],"metadata":{"id":"w203IDxrjeOY"}}]}